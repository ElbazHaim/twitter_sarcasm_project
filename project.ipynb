{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sarcasm & Irony Detection Project\n",
    "### By Asaf Levi & Haim Elbaz \n",
    "In this project, we will build several machine learning models model to detect sarcasm and irony in tweets, and compare their performance between models and preprocessing levels. \n",
    "\n",
    "We will be using the scikit-learn library for building our classifiers, with NLTK for natural language processing tools.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We will be using a labeled dataset of tweets, built as part of the research presented in the paper \"Quantitative Analysis of the Differences between Sarcasm and Irony (Klinger and Litvak, 2016)\".\n",
    "\n",
    "The dataset contains data labeled as \"regular\", \"sarcasm\", \"irony\" and \"figurative\", as tagged by the tweet's writer. For our purposes, we will unite sarcasm and irony into a single category, omitting \"figurative\". \n",
    "\n",
    "## Steps Involved\n",
    "\n",
    "1. Data Cleaning: We will clean and preprocess the tweet data by removing emojis, URLs, usernames, etc., handling necessary text transformations.\n",
    "\n",
    "2. Feature Extraction: We will extract relevant features from the preprocessed tweets, such as bag-of-words, TF-IDF representations, and sentiment analysis.  These features will be used as input to our machine learning model.\n",
    "\n",
    "3. Model Training: We will use scikit-learn's machine learning algorithms - Logistic Regression, Support Vector Machine Classifier and Random Forest Classifier  to train sarcasm-irony detection models on the labeled dataset.\n",
    "\n",
    "4. Model Evaluation: We will evaluate the performance of our models with the help of a designated test dataset that will go through the same processing steps described. We will evaluate the models' performance using various metrics, such as accuracy, precision, recall, and F1 score. \n",
    "\n",
    "5. Prediction: Once our model is trained and evaluated, we can use it to predict sarcasm and irony in new, unseen tweets.\n",
    "\n",
    "## Code Structure\n",
    "\n",
    "To keep our notebook organized, we will store custom functions in a separate `helpers.py` file. This file will contain functions for data preprocessing, feature extraction, and any other utility functions we may need throughout the project. We will import these functions as needed in our notebook.\n",
    "\n",
    "Let's get started with importing the necessary libraries and loading the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from helpers import preprocessing_pipeline, count_syntactic_features\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set\n",
    "raw_training_data = pd.read_csv(\"data/train.csv\")\n",
    "training_data = preprocessing_pipeline(raw_training_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data from twitter, it would benefit to use a twitter-designated tokenizer which recognizes hashtags, usernames, urls, and emojis. After tokenizing each tweet, we use get TF-IDF for each word in the dataset. \n",
    "\n",
    "It is worth mentioning that we tried using simple bag of words (CountVectorizer), but the results using TF-IDF were much better. TF-IDF takes into account the importance of the word within its tweet, which seems to be quite important when it comes to tweets, in particular in large dataset, as seen in \"Sentiment Analysis on COVID Tweets: An Experimental Analysis on the Impact of Count Vectorizer and TF-IDF on Sentiment Predictions using Deep Learning Models (Raza et al., 2021)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()\n",
    "def tokenize(tweet):\n",
    "    return tweet_tokenizer.tokenize(tweet)\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "training_data_level_1 = vectorizer.fit_transform(training_data[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data_level_1\n",
    "y = training_data[\"class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = [\n",
    "        (\n",
    "            RandomForestClassifier(random_state=42),{\n",
    "                \"class_weight\" : [ \"balanced\"], # None\n",
    "                \"min_samples_leaf\" : [i for i in range(3, 63, 10)],\n",
    "                \"n_estimators\" : [i for i in range(5, 115, 15)],\n",
    "                \"n_jobs\" : [7]\n",
    "            }\n",
    "    ),\n",
    "        (\n",
    "            LinearSVC(random_state=42),{\n",
    "                \"C\" : [0.05, 0.5, 1],\n",
    "                \"class_weight\" : [\"balanced\"],\n",
    "            }\n",
    "    ),\n",
    "        (\n",
    "            LogisticRegression(random_state=42),{\n",
    "                \"max_iter\": [125, 150],\n",
    "                \"class_weight\" : [\"balanced\"],\n",
    "                \"n_jobs\" : [7],\n",
    "    })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_gridsearch(X_train, y_train, models_params):\n",
    "    results = pd.DataFrame()\n",
    "    for model, param_grid in models_params:\n",
    "        gs = GridSearchCV(estimator=model, \n",
    "                            error_score='raise',\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='f1')\n",
    "        gs.fit(X=X_train, y=y_train)\n",
    "        results = pd.concat([results , pd.DataFrame([\n",
    "    {\n",
    "    'model_type' : model,\n",
    "    'parameters' : params,\n",
    "    'score' : score,\n",
    "    }\n",
    "    for params, score in zip(gs.cv_results_[\"params\"],gs.cv_results_[\"mean_test_score\"],\n",
    "    )])])\n",
    "    return results.sort_values(by='score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model_results = do_gridsearch(X_train, y_train, models_params)\n",
    "tfidf_model_results.to_csv(\"tfidf_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Stopwords</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fav moment in sepp blatter vid ( 0:20 ) : `` w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just found this while walking my human ....</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'disrespected the wife of prophet ' - pseudo l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do you know that super yeay satisfying feeling...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you 're going to call someone ignorant and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6705</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  class    neg    neu  \\\n",
       "0  fav moment in sepp blatter vid ( 0:20 ) : `` w...      1    0.0  0.778   \n",
       "1        just found this while walking my human ....      1    0.0    1.0   \n",
       "2  'disrespected the wife of prophet ' - pseudo l...      1  0.217  0.652   \n",
       "3  do you know that super yeay satisfying feeling...      1    0.0  0.704   \n",
       "4  if you 're going to call someone ignorant and ...      1  0.234  0.766   \n",
       "\n",
       "     pos compound Stopwords Nouns Verbs Adverbs Adjectives Pronouns length  \n",
       "0  0.222   0.6908        10     5     1       1          2        0    116  \n",
       "1    0.0      0.0         4     2     2       0          0        0     43  \n",
       "2   0.13   -0.296         3     6     2       0          0        0     80  \n",
       "3  0.296   0.8126        11     3     6       1          1        0    120  \n",
       "4    0.0  -0.6705         9     3     4       1          3        0    104  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = pd.DataFrame(columns=[\"neg\", \"neu\", \"pos\", \"compound\", 'Stopwords', 'Nouns', 'Verbs', 'Adverbs', 'Adjectives', 'Pronouns', \"length\"])\n",
    "training_data = training_data.join(new_columns)\n",
    "\n",
    "for index, row in training_data.iterrows():\n",
    "    tweet = row[0]\n",
    "\n",
    "    scores = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "\n",
    "    for sentiment, score in scores.items():\n",
    "        training_data.loc[index, sentiment] = score\n",
    "        \n",
    "    syntax_counts = count_syntactic_features(tweet)\n",
    "    for syntax, count in syntax_counts.items():\n",
    "        training_data.loc[index, syntax] = count\n",
    "        \n",
    "    training_data.loc[index, \"length\"] = len(tweet)\n",
    "\n",
    "training_data = training_data.drop_duplicates()\n",
    "training_data = training_data.reset_index(drop=True)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_columns = training_data.columns\n",
    "processed_training_data = training_data.copy()\n",
    "tf_idf_results = vectorizer.fit_transform(training_data[\"tweets\"])\n",
    "processed_training_data.drop(columns=[\"tweets\", \"class\"], inplace=True)\n",
    "training_data_level_2 = csr_matrix(processed_training_data.to_numpy(dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = hstack([tf_idf_results, training_data_level_2])\n",
    "y = training_data[\"class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=5432)\n",
    "bow_features_model_results = do_gridsearch(X_train, y_train, models_params)\n",
    "bow_features_model_results.to_csv(\"tfidf_sentiment_syntax.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_vectorizer = TfidfVectorizer(tokenizer=tokenize, \n",
    "                                ngram_range=(2, 2), \n",
    "                                max_features=50000)\n",
    "bigram = bi_vectorizer.fit_transform(training_data[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = hstack([tf_idf_results, training_data_level_2, bigram])\n",
    "y = training_data[\"class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=99101)\n",
    "bigram_model_results = do_gridsearch(X_train, y_train, models_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model_results.to_csv(\"tfidf_sentiment_syntax_bigram.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Process Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "raw_test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "test_data = preprocessing_pipeline(raw_test_data)\n",
    "y_test = test_data[\"class\"]\n",
    "training_data = preprocessing_pipeline(raw_training_data)\n",
    "whole_dataset = pd.concat([test_data, training_data])\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "def tokenize(tweet):\n",
    "    return tweet_tokenizer.tokenize(tweet)\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "\n",
    "vectorizer.fit(whole_dataset[\"tweets\"])\n",
    "X = vectorizer.transform(training_data[\"tweets\"])\n",
    "y = training_data[\"class\"]\n",
    "\n",
    "X_pred = vectorizer.transform(test_data[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.646584</td>\n",
       "      <td>0.888520</td>\n",
       "      <td>0.814486</td>\n",
       "      <td>0.767552</td>\n",
       "      <td>0.821933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.718900</td>\n",
       "      <td>0.850784</td>\n",
       "      <td>0.814486</td>\n",
       "      <td>0.784842</td>\n",
       "      <td>0.814486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.680827</td>\n",
       "      <td>0.869242</td>\n",
       "      <td>0.814486</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.817385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1672.000000</td>\n",
       "      <td>4403.000000</td>\n",
       "      <td>0.814486</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.646584     0.888520  0.814486     0.767552      0.821933\n",
       "recall        0.718900     0.850784  0.814486     0.784842      0.814486\n",
       "f1-score      0.680827     0.869242  0.814486     0.775035      0.817385\n",
       "support    1672.000000  4403.000000  0.814486  6075.000000   6075.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight=\"balanced\",\n",
    "                               min_samples_leaf=3,\n",
    "                               n_estimators=110,\n",
    "                               n_jobs=7,\n",
    "                               random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.576654</td>\n",
       "      <td>0.938330</td>\n",
       "      <td>0.827654</td>\n",
       "      <td>0.757492</td>\n",
       "      <td>0.859029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.834071</td>\n",
       "      <td>0.827654</td>\n",
       "      <td>0.819438</td>\n",
       "      <td>0.827654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.671890</td>\n",
       "      <td>0.883134</td>\n",
       "      <td>0.827654</td>\n",
       "      <td>0.777512</td>\n",
       "      <td>0.836817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1332.000000</td>\n",
       "      <td>4743.000000</td>\n",
       "      <td>0.827654</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.576654     0.938330  0.827654     0.757492      0.859029\n",
       "recall        0.804805     0.834071  0.827654     0.819438      0.827654\n",
       "f1-score      0.671890     0.883134  0.827654     0.777512      0.836817\n",
       "support    1332.000000  4743.000000  0.827654  6075.000000   6075.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight=None,\n",
    "                            max_iter=150,\n",
    "                            n_jobs=7,\n",
    "                            random_state=99101)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.740183</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.805597</td>\n",
       "      <td>0.787312</td>\n",
       "      <td>0.802261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.663452</td>\n",
       "      <td>0.879280</td>\n",
       "      <td>0.805597</td>\n",
       "      <td>0.771366</td>\n",
       "      <td>0.805597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.699720</td>\n",
       "      <td>0.856274</td>\n",
       "      <td>0.805597</td>\n",
       "      <td>0.777997</td>\n",
       "      <td>0.802826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2074.000000</td>\n",
       "      <td>4001.000000</td>\n",
       "      <td>0.805597</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.740183     0.834440  0.805597     0.787312      0.802261\n",
       "recall        0.663452     0.879280  0.805597     0.771366      0.805597\n",
       "f1-score      0.699720     0.856274  0.805597     0.777997      0.802826\n",
       "support    2074.000000  4001.000000  0.805597  6075.000000   6075.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=0.5,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=99101)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Process Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = pd.DataFrame(columns=[\"neg\", \"neu\", \"pos\", \"compound\", 'Stopwords', 'Nouns', 'Verbs', 'Adverbs', 'Adjectives', 'Pronouns', \"length\"])\n",
    "training_data = training_data.join(new_columns)\n",
    "\n",
    "for index, row in training_data.iterrows():\n",
    "    tweet = row[0]\n",
    "\n",
    "    scores = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "\n",
    "    for sentiment, score in scores.items():\n",
    "        training_data.loc[index, sentiment] = score\n",
    "        \n",
    "    syntax_counts = count_syntactic_features(tweet)\n",
    "    for syntax, count in syntax_counts.items():\n",
    "        training_data.loc[index, syntax] = count\n",
    "        \n",
    "    training_data.loc[index, \"length\"] = len(tweet)\n",
    "\n",
    "training_data = training_data.drop_duplicates()\n",
    "training_data = training_data.reset_index(drop=True)\n",
    "processed_columns = training_data.columns\n",
    "processed_training_data = training_data.copy()\n",
    "tf_idf_results = vectorizer.transform(training_data[\"tweets\"])\n",
    "processed_training_data.drop(columns=[\"tweets\", \"class\"], inplace=True)\n",
    "training_data_level_2 = csr_matrix(processed_training_data.to_numpy(dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack([tf_idf_results, training_data_level_2])\n",
    "y = training_data[\"class\"]\n",
    "\n",
    "new_columns = pd.DataFrame(columns=[\"neg\", \"neu\", \"pos\", \"compound\", 'Stopwords', 'Nouns', 'Verbs', 'Adverbs', 'Adjectives', 'Pronouns', \"length\"])\n",
    "testing_data = test_data.join(new_columns)\n",
    "\n",
    "for index, row in testing_data.iterrows():\n",
    "    tweet = row[0]\n",
    "\n",
    "    scores = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "\n",
    "    for sentiment, score in scores.items():\n",
    "        testing_data.loc[index, sentiment] = score\n",
    "        \n",
    "    syntax_counts = count_syntactic_features(tweet)\n",
    "    for syntax, count in syntax_counts.items():\n",
    "        testing_data.loc[index, syntax] = count\n",
    "        \n",
    "    testing_data.loc[index, \"length\"] = len(tweet)\n",
    "\n",
    "testing_data = testing_data.reset_index(drop=True)\n",
    "\n",
    "processed_columns = testing_data.columns\n",
    "processed_testing_data = testing_data.copy()\n",
    "tf_idf_results = vectorizer.transform(testing_data[\"tweets\"])\n",
    "processed_testing_data.drop(columns=[\"tweets\", \"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = hstack([X_pred, csr_matrix(processed_testing_data.to_numpy(dtype=np.float32))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.679935</td>\n",
       "      <td>0.839896</td>\n",
       "      <td>0.790947</td>\n",
       "      <td>0.759916</td>\n",
       "      <td>0.788840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.651882</td>\n",
       "      <td>0.856141</td>\n",
       "      <td>0.790947</td>\n",
       "      <td>0.754012</td>\n",
       "      <td>0.790947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.665613</td>\n",
       "      <td>0.847941</td>\n",
       "      <td>0.790947</td>\n",
       "      <td>0.756777</td>\n",
       "      <td>0.789746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1939.000000</td>\n",
       "      <td>4136.000000</td>\n",
       "      <td>0.790947</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.679935     0.839896  0.790947     0.759916      0.788840\n",
       "recall        0.651882     0.856141  0.790947     0.754012      0.790947\n",
       "f1-score      0.665613     0.847941  0.790947     0.756777      0.789746\n",
       "support    1939.000000  4136.000000  0.790947  6075.000000   6075.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight=\"balanced\",\n",
    "                               min_samples_leaf=3,\n",
    "                               n_estimators=110,\n",
    "                               n_jobs=7,\n",
    "                               random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.736417</td>\n",
       "      <td>0.745493</td>\n",
       "      <td>0.742716</td>\n",
       "      <td>0.740955</td>\n",
       "      <td>0.741845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.865125</td>\n",
       "      <td>0.742716</td>\n",
       "      <td>0.712866</td>\n",
       "      <td>0.742716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.636596</td>\n",
       "      <td>0.800866</td>\n",
       "      <td>0.742716</td>\n",
       "      <td>0.718731</td>\n",
       "      <td>0.734834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2442.000000</td>\n",
       "      <td>3633.000000</td>\n",
       "      <td>0.742716</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.736417     0.745493  0.742716     0.740955      0.741845\n",
       "recall        0.560606     0.865125  0.742716     0.712866      0.742716\n",
       "f1-score      0.636596     0.800866  0.742716     0.718731      0.734834\n",
       "support    2442.000000  3633.000000  0.742716  6075.000000   6075.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight=\"balanced\",\n",
    "                            max_iter=125,\n",
    "                            n_jobs=7,\n",
    "                            random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.736417</td>\n",
       "      <td>0.829459</td>\n",
       "      <td>0.800988</td>\n",
       "      <td>0.782938</td>\n",
       "      <td>0.797480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.655651</td>\n",
       "      <td>0.877101</td>\n",
       "      <td>0.800988</td>\n",
       "      <td>0.766376</td>\n",
       "      <td>0.800988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.693691</td>\n",
       "      <td>0.852615</td>\n",
       "      <td>0.800988</td>\n",
       "      <td>0.773153</td>\n",
       "      <td>0.797992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2088.000000</td>\n",
       "      <td>3987.000000</td>\n",
       "      <td>0.800988</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.736417     0.829459  0.800988     0.782938      0.797480\n",
       "recall        0.655651     0.877101  0.800988     0.766376      0.800988\n",
       "f1-score      0.693691     0.852615  0.800988     0.773153      0.797992\n",
       "support    2088.000000  3987.000000  0.800988  6075.000000   6075.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=0.05,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Process Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bi_vectorizer = TfidfVectorizer(tokenizer=tokenize, \n",
    "                                ngram_range=(2, 2), \n",
    "                                max_features=50000)\n",
    "bi_vectorizer.fit(whole_dataset[\"tweets\"])\n",
    "\n",
    "train_bigram = bi_vectorizer.transform(training_data[\"tweets\"])\n",
    "test_bigram = bi_vectorizer.transform(testing_data[\"tweets\"])\n",
    "X = hstack([train_bigram, X])\n",
    "X_pred = hstack([test_bigram, X_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.721356</td>\n",
       "      <td>0.694260</td>\n",
       "      <td>0.702551</td>\n",
       "      <td>0.707808</td>\n",
       "      <td>0.705990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.509886</td>\n",
       "      <td>0.849637</td>\n",
       "      <td>0.702551</td>\n",
       "      <td>0.679762</td>\n",
       "      <td>0.702551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.597460</td>\n",
       "      <td>0.764130</td>\n",
       "      <td>0.702551</td>\n",
       "      <td>0.680795</td>\n",
       "      <td>0.691975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2630.000000</td>\n",
       "      <td>3445.000000</td>\n",
       "      <td>0.702551</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.721356     0.694260  0.702551     0.707808      0.705990\n",
       "recall        0.509886     0.849637  0.702551     0.679762      0.702551\n",
       "f1-score      0.597460     0.764130  0.702551     0.680795      0.691975\n",
       "support    2630.000000  3445.000000  0.702551  6075.000000   6075.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight=\"balanced\",\n",
    "                            max_iter=125,\n",
    "                            n_jobs=7,\n",
    "                            random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.699301</td>\n",
       "      <td>0.839658</td>\n",
       "      <td>0.796708</td>\n",
       "      <td>0.76948</td>\n",
       "      <td>0.794005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.863625</td>\n",
       "      <td>0.796708</td>\n",
       "      <td>0.76076</td>\n",
       "      <td>0.796708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.851473</td>\n",
       "      <td>0.796708</td>\n",
       "      <td>0.76472</td>\n",
       "      <td>0.795037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1976.000000</td>\n",
       "      <td>4099.000000</td>\n",
       "      <td>0.796708</td>\n",
       "      <td>6075.00000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy   macro avg  weighted avg\n",
       "precision     0.699301     0.839658  0.796708     0.76948      0.794005\n",
       "recall        0.657895     0.863625  0.796708     0.76076      0.796708\n",
       "f1-score      0.677966     0.851473  0.796708     0.76472      0.795037\n",
       "support    1976.000000  4099.000000  0.796708  6075.00000   6075.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight=\"balanced\",\n",
    "                               min_samples_leaf=3,\n",
    "                               n_estimators=80,\n",
    "                               n_jobs=7,\n",
    "                               random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.555675</td>\n",
       "      <td>0.942837</td>\n",
       "      <td>0.824362</td>\n",
       "      <td>0.749256</td>\n",
       "      <td>0.861644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.810832</td>\n",
       "      <td>0.827953</td>\n",
       "      <td>0.824362</td>\n",
       "      <td>0.819392</td>\n",
       "      <td>0.824362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.881668</td>\n",
       "      <td>0.824362</td>\n",
       "      <td>0.770550</td>\n",
       "      <td>0.835062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1274.000000</td>\n",
       "      <td>4801.000000</td>\n",
       "      <td>0.824362</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>6075.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1  accuracy    macro avg  weighted avg\n",
       "precision     0.555675     0.942837  0.824362     0.749256      0.861644\n",
       "recall        0.810832     0.827953  0.824362     0.819392      0.824362\n",
       "f1-score      0.659432     0.881668  0.824362     0.770550      0.835062\n",
       "support    1274.000000  4801.000000  0.824362  6075.000000   6075.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=0.5,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_pred)\n",
    "pd.DataFrame(classification_report(y_pred, y_test, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
