{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from helpers import preprocessing_pipeline, count_syntactic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_set = pd.read_csv(\"data/train.csv\")\n",
    "train_set = preprocessing_pipeline(raw_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_column_names = columns=train_set.columns.to_list()\n",
    "new_column_names = [\"neg\", \"neu\", \"pos\", \"compound\", 'Stopwords', 'Nouns', 'Verbs', 'Adverbs', 'Adjectives', 'Pronouns', \"length\"]\n",
    "train_set = train_set.reindex(columns=existing_column_names + new_column_names)\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_set.iterrows():\n",
    "    tweet = row[0]\n",
    "    scores = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "    \n",
    "    for sentiment, score in scores.items():\n",
    "        train_set.loc[index, sentiment] = score\n",
    "        \n",
    "    syntax_counts = count_syntactic_features(tweet)\n",
    "    for syntax, count in syntax_counts.items():\n",
    "        train_set.loc[index, syntax] = count\n",
    "        \n",
    "    train_set.loc[index, \"length\"] = len(tweet)\n",
    "    \n",
    "train_set = train_set.drop_duplicates() \n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(train_set[\"tweets\"])\n",
    "bow_data = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())\n",
    "bow_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_set[\"class\"]\n",
    "train_set.drop(columns=[\"tweets\", \"class\"], inplace=True)\n",
    "X = pd.concat(bow_data, train_set)\n",
    "X.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
