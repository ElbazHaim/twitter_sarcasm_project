{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from helpers import preprocessing_pipeline, count_syntactic_features\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_data = pd.read_csv(\"data/train.csv\")\n",
    "training_data = preprocessing_pipeline(raw_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = pd.DataFrame(columns=[\"neg\", \"neu\", \"pos\", \"compound\", 'Stopwords', 'Nouns', 'Verbs', 'Adverbs', 'Adjectives', 'Pronouns', \"length\"])\n",
    "training_data = training_data.join(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    training_data = pd.read_csv(\"training_data.csv\")\n",
    "    training_data.head()\n",
    "    \n",
    "except FileNotFoundError as error:\n",
    "    for index, row in training_data.iterrows():\n",
    "        tweet = row[0]\n",
    "        \n",
    "    scores = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "    \n",
    "    for sentiment, score in scores.items():\n",
    "        training_data.loc[index, sentiment] = score\n",
    "        \n",
    "    syntax_counts = count_syntactic_features(tweet)\n",
    "    for syntax, count in syntax_counts.items():\n",
    "        training_data.loc[index, syntax] = count\n",
    "        \n",
    "    training_data.loc[index, \"length\"] = len(tweet)\n",
    "    \n",
    "    training_data = training_data.drop_duplicates()\n",
    "    training_data = training_data.reset_index(drop=True)\n",
    "    training_data.to_csv(\"training_data.csv\")\n",
    "    training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()\n",
    "def tokenize(tweet):\n",
    "    return tweet_tokenizer.tokenize(tweet)\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "bag_of_words = vectorizer.fit_transform(training_data[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_columns = processed_training_data.columns\n",
    "y = training_data[\"class\"]\n",
    "processed_training_data = training_data.copy()\n",
    "processed_training_data.drop(columns=[\"tweets\", \"class\"], inplace=True)\n",
    "sparse_training_data = csr_matrix(processed_training_data.to_numpy(dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack([bag_of_words, sparse_training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=1337)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LinearSVC()\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestClassifier()\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred = model3.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_vectorizer = CountVectorizer(tokenizer=tokenize, \n",
    "#                                 ngram_range=(2, 2), \n",
    "#                                 max_features=50000)\n",
    "# bigram = vectorizer.fit_transform(training_data[\"tweets\"])\n",
    "# bigram_data = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = pd.concat([X, bigram_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X2, y, \n",
    "#                                                     test_size=0.3, \n",
    "#                                                     random_state=42)\n",
    "\n",
    "# model = LogisticRegression(njobs=-1)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
