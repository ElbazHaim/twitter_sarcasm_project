{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from helpers import preprocessing_pipeline, count_syntactic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_set = pd.read_csv(\"data/train.csv\")\n",
    "train_set = preprocessing_pipeline(raw_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Stopwords</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21238</th>\n",
       "      <td>fav moment in sepp blatter vid ( 0:20 ) : `` w...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>just found this while walking my human ....</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21240</th>\n",
       "      <td>'disrespected the wife of prophet ' - pseudo l...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21241</th>\n",
       "      <td>do you know that super yeay satisfying feeling...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21242</th>\n",
       "      <td>if you 're going to call someone ignorant and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets  class  neg  neu  \\\n",
       "21238  fav moment in sepp blatter vid ( 0:20 ) : `` w...      1  NaN  NaN   \n",
       "21239        just found this while walking my human ....      1  NaN  NaN   \n",
       "21240  'disrespected the wife of prophet ' - pseudo l...      1  NaN  NaN   \n",
       "21241  do you know that super yeay satisfying feeling...      1  NaN  NaN   \n",
       "21242  if you 're going to call someone ignorant and ...      1  NaN  NaN   \n",
       "\n",
       "       pos compound Stopwords Nouns Verbs Adverbs Adjectives Pronouns length  \n",
       "21238  NaN      NaN       NaN   NaN   NaN     NaN        NaN      NaN    NaN  \n",
       "21239  NaN      NaN       NaN   NaN   NaN     NaN        NaN      NaN    NaN  \n",
       "21240  NaN      NaN       NaN   NaN   NaN     NaN        NaN      NaN    NaN  \n",
       "21241  NaN      NaN       NaN   NaN   NaN     NaN        NaN      NaN    NaN  \n",
       "21242  NaN      NaN       NaN   NaN   NaN     NaN        NaN      NaN    NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = pd.DataFrame(columns=[\"neg\", \"neu\", \"pos\", \"compound\", 'Stopwords', 'Nouns', 'Verbs', 'Adverbs', 'Adjectives', 'Pronouns', \"length\"])\n",
    "train_set = train_set.join(new_columns)\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Stopwords</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21238</th>\n",
       "      <td>fav moment in sepp blatter vid ( 0:20 ) : `` w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>just found this while walking my human ....</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21240</th>\n",
       "      <td>'disrespected the wife of prophet ' - pseudo l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21241</th>\n",
       "      <td>do you know that super yeay satisfying feeling...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21242</th>\n",
       "      <td>if you 're going to call someone ignorant and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6705</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets  class    neg    neu  \\\n",
       "21238  fav moment in sepp blatter vid ( 0:20 ) : `` w...      1  0.000  0.778   \n",
       "21239        just found this while walking my human ....      1  0.000  1.000   \n",
       "21240  'disrespected the wife of prophet ' - pseudo l...      1  0.217  0.652   \n",
       "21241  do you know that super yeay satisfying feeling...      1  0.000  0.704   \n",
       "21242  if you 're going to call someone ignorant and ...      1  0.234  0.766   \n",
       "\n",
       "         pos  compound  Stopwords  Nouns  Verbs  Adverbs  Adjectives  \\\n",
       "21238  0.222    0.6908       10.0    5.0    1.0      1.0         2.0   \n",
       "21239  0.000    0.0000        4.0    2.0    2.0      0.0         0.0   \n",
       "21240  0.130   -0.2960        3.0    6.0    2.0      0.0         0.0   \n",
       "21241  0.296    0.8126       11.0    3.0    6.0      1.0         1.0   \n",
       "21242  0.000   -0.6705        9.0    3.0    4.0      1.0         3.0   \n",
       "\n",
       "       Pronouns  length  \n",
       "21238       0.0   116.0  \n",
       "21239       0.0    43.0  \n",
       "21240       0.0    80.0  \n",
       "21241       0.0   120.0  \n",
       "21242       0.0   104.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in train_set.iterrows():\n",
    "    tweet = row[0]\n",
    "    scores = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "    \n",
    "    for sentiment, score in scores.items():\n",
    "        train_set.loc[index, sentiment] = score\n",
    "        \n",
    "    syntax_counts = count_syntactic_features(tweet)\n",
    "    for syntax, count in syntax_counts.items():\n",
    "        train_set.loc[index, syntax] = count\n",
    "        \n",
    "    train_set.loc[index, \"length\"] = len(tweet)\n",
    "    \n",
    "train_set = train_set.drop_duplicates()\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haim/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000009</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>000th</th>\n",
       "      <th>000yrs</th>\n",
       "      <th>001</th>\n",
       "      <th>003</th>\n",
       "      <th>007</th>\n",
       "      <th>...</th>\n",
       "      <th>आरक</th>\n",
       "      <th>छड</th>\n",
       "      <th>नव</th>\n",
       "      <th>वर</th>\n",
       "      <th>षण</th>\n",
       "      <th>सरक</th>\n",
       "      <th>ભક</th>\n",
       "      <th>રક</th>\n",
       "      <th>ષક</th>\n",
       "      <th>ᵀºᵗªˡˡʸ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40657 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000009  000ft  000km  000th  000yrs  001  003  007  ...  आरक  छड  \\\n",
       "0   0    0       0      0      0      0       0    0    0    0  ...    0   0   \n",
       "1   0    0       0      0      0      0       0    0    0    0  ...    0   0   \n",
       "2   0    0       0      0      0      0       0    0    0    0  ...    0   0   \n",
       "3   0    0       0      0      0      0       0    0    0    0  ...    0   0   \n",
       "4   0    0       0      0      0      0       0    0    0    0  ...    0   0   \n",
       "\n",
       "   नव  वर  षण  सरक  ભક  રક  ષક  ᵀºᵗªˡˡʸ  \n",
       "0   0   0   0    0   0   0   0        0  \n",
       "1   0   0   0    0   0   0   0        0  \n",
       "2   0   0   0    0   0   0   0        0  \n",
       "3   0   0   0    0   0   0   0        0  \n",
       "4   0   0   0    0   0   0   0        0  \n",
       "\n",
       "[5 rows x 40657 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(train_set[\"tweets\"])\n",
    "bow_data = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())\n",
    "bow_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_set[\"class\"]\n",
    "train_set.drop(columns=[\"tweets\", \"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['pos', 'compound', 'length'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/haim/studies/nlp/twitter_sarcasm_project/2-feature_engineering.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/haim/studies/nlp/twitter_sarcasm_project/2-feature_engineering.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X \u001b[39m=\u001b[39m train_set[:\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mjoin(bow_data[:\u001b[39m1\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haim/studies/nlp/twitter_sarcasm_project/2-feature_engineering.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:9254\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   9100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[1;32m   9101\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9102\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9107\u001b[0m     sort: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   9108\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9109\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9110\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[1;32m   9111\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9252\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[1;32m   9253\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_join_compat(\n\u001b[1;32m   9255\u001b[0m         other, on\u001b[39m=\u001b[39;49mon, how\u001b[39m=\u001b[39;49mhow, lsuffix\u001b[39m=\u001b[39;49mlsuffix, rsuffix\u001b[39m=\u001b[39;49mrsuffix, sort\u001b[39m=\u001b[39;49msort\n\u001b[1;32m   9256\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:9285\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   9276\u001b[0m     \u001b[39mif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   9277\u001b[0m         \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   9278\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[1;32m   9279\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9283\u001b[0m             sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m   9284\u001b[0m         )\n\u001b[0;32m-> 9285\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   9286\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   9287\u001b[0m         other,\n\u001b[1;32m   9288\u001b[0m         left_on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9289\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   9290\u001b[0m         left_index\u001b[39m=\u001b[39;49mon \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   9291\u001b[0m         right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   9292\u001b[0m         suffixes\u001b[39m=\u001b[39;49m(lsuffix, rsuffix),\n\u001b[1;32m   9293\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9294\u001b[0m     )\n\u001b[1;32m   9295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   9296\u001b[0m     \u001b[39mif\u001b[39;00m on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:122\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    107\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    108\u001b[0m         left,\n\u001b[1;32m    109\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    121\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:718\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m    716\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 718\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    719\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuffixes\n\u001b[1;32m    720\u001b[0m )\n\u001b[1;32m    722\u001b[0m lindexers \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: left_indexer} \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    723\u001b[0m rindexers \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: right_indexer} \u001b[39mif\u001b[39;00m right_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2313\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2310\u001b[0m lsuffix, rsuffix \u001b[39m=\u001b[39m suffixes\n\u001b[1;32m   2312\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lsuffix \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rsuffix:\n\u001b[0;32m-> 2313\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns overlap but no suffix specified: \u001b[39m\u001b[39m{\u001b[39;00mto_rename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrenamer\u001b[39m(x, suffix):\n\u001b[1;32m   2316\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2317\u001b[0m \u001b[39m    Rename the left and right indices.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[39m    x : renamed column name\u001b[39;00m\n\u001b[1;32m   2330\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['pos', 'compound', 'length'], dtype='object')"
     ]
    }
   ],
   "source": [
    "X = train_set[:1].join(bow_data[:1])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Stopwords</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [neg, neu, pos, compound, Stopwords, Nouns, Verbs, Adverbs, Adjectives, Pronouns, length]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
